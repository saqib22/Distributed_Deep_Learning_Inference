{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # conv layers: (in_channel size, out_channels size, kernel_size, stride, padding)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(16, 8, 5, stride=1, padding=2)\n",
    "\n",
    "        # max pooling (kernel_size, stride)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully conected layers:\n",
    "        self.layer1 = nn.Linear(4*4*8, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        # the autoencoder has 3 con layers and 3 deconv layers (transposed conv). All layers but the last have ReLu\n",
    "        # activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 4 * 4 * 8)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.dropout(x, 0.5, training=training)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        # a function to predict the labels of a batch of inputs\n",
    "        x = F.softmax(self.forward(x, training=False))\n",
    "        return x\n",
    "\n",
    "    def accuracy(self, x, y):\n",
    "        # a function to calculate the accuracy of label prediction for a batch of inputs\n",
    "        #   x: a batch of inputs\n",
    "        #   y: the true labels associated with x\n",
    "        prediction = self.predict(x)\n",
    "        maxs, indices = torch.max(prediction, 1)\n",
    "        acc = 100 * torch.sum(torch.eq(indices.float(), y.float()).float())/y.size()[0]\n",
    "        return acc.cpu().data[0]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = CNN(10)\n",
    "model.cuda()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "state = torch.load('cnn.pth')\n",
    "model.load_state_dict(state)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "modules = []\n",
    "for name, module in model.named_modules():\n",
    "    modules.append(name)\n",
    "print(modules) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', 'conv1', 'conv2', 'conv3', 'pool', 'layer1', 'layer2', 'layer3']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "getattr(model, modules[1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]],\n",
       "\n",
       "\n",
       "        [[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]],\n",
       "\n",
       "\n",
       "        [[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]],\n",
       "\n",
       "\n",
       "        [[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]],\n",
       "\n",
       "\n",
       "        [[[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          ...,\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "          [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]],\n",
       "\n",
       "         [[ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          ...,\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312],\n",
       "          [ 0.1312,  0.1312,  0.1312,  ...,  0.1312,  0.1312,  0.1312]],\n",
       "\n",
       "         [[-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          ...,\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
       "          [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          ...,\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604],\n",
       "          [ 0.1604,  0.1604,  0.1604,  ...,  0.1604,  0.1604,  0.1604]],\n",
       "\n",
       "         [[-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          ...,\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340],\n",
       "          [-0.0340, -0.0340, -0.0340,  ..., -0.0340, -0.0340, -0.0340]],\n",
       "\n",
       "         [[-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          ...,\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797],\n",
       "          [-0.0797, -0.0797, -0.0797,  ..., -0.0797, -0.0797, -0.0797]]]],\n",
       "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "batch_size = 500   # Number of samples in each batch\n",
    "epoch_num = 20      # Number of epochs to train the network\n",
    "lr = 0.0005        # Learning rate\n",
    "\n",
    "def next_batch(train=True):\n",
    "    # A function to read the next batch of MNIST images and labels\n",
    "    # Args:\n",
    "    #   train: a boolean array, if True it will return the next train batch, otherwise the next test batch\n",
    "    # Returns:\n",
    "    #   batch_img: a pytorch Variable of size [batch_size, 1, 32, 32].\n",
    "    #   batch_label: a pytorch Variable of size [batch_size, ].\n",
    "\n",
    "    if train:\n",
    "        batch_img, batch_label = mnist.train.next_batch(batch_size)\n",
    "    else:\n",
    "        batch_img, batch_label = mnist.test.next_batch(batch_size)\n",
    "\n",
    "    # reshape the sample to a batch of images in pytorch order (batch, channels, height, width)\n",
    "    batch_img = batch_img.reshape((-1, 1, 28, 28))\n",
    "\n",
    "    # resize the images to (32, 32)\n",
    "    resized_imgs = np.zeros((batch_img.shape[0], 1, 32, 32))\n",
    "    for i in range(batch_img.shape[0]):\n",
    "        resized_imgs[i, 0, ...] = transform.resize(batch_img[i, 0,...], (32, 32))\n",
    "\n",
    "    batch_label = torch.from_numpy(batch_label).long()  # convert the numpy array into torch tensor\n",
    "    batch_label = Variable(batch_label).cuda()          # create a torch variable and transfer it into GPU\n",
    "\n",
    "    resized_imgs = torch.from_numpy(resized_imgs).float()     # convert the numpy array into torch tensor\n",
    "    resized_imgs = Variable(resized_imgs).cuda()              # create a torch variable and transfer it into GPU\n",
    "    return resized_imgs, batch_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "features, labels = next_batch(train=False)\n",
    "\n",
    "np.argmax(model.predict(features).cpu().detach().numpy(), axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/saqib/.local/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6, 6, 4, 1, 6, 0, 5, 9, 3, 7, 6, 1, 3, 3, 5, 2, 1, 8, 3, 8, 9, 1,\n",
       "       8, 5, 1, 6, 9, 5, 7, 7, 5, 8, 1, 7, 0, 8, 0, 4, 7, 5, 8, 7, 2, 1,\n",
       "       5, 4, 0, 3, 7, 7, 8, 7, 3, 7, 6, 5, 2, 2, 9, 8, 9, 0, 2, 9, 0, 7,\n",
       "       9, 7, 9, 7, 3, 4, 4, 5, 0, 5, 9, 9, 9, 7, 9, 7, 7, 6, 0, 0, 9, 3,\n",
       "       0, 7, 0, 3, 6, 1, 9, 5, 4, 0, 3, 1, 8, 9, 4, 8, 0, 1, 7, 2, 8, 7,\n",
       "       0, 2, 2, 7, 6, 1, 1, 6, 6, 1, 3, 9, 2, 8, 9, 8, 9, 9, 2, 8, 3, 8,\n",
       "       9, 4, 5, 5, 4, 7, 6, 3, 9, 5, 1, 7, 6, 5, 0, 8, 5, 9, 6, 3, 5, 3,\n",
       "       0, 9, 5, 7, 5, 5, 1, 4, 9, 9, 3, 3, 0, 2, 8, 5, 7, 5, 2, 2, 1, 6,\n",
       "       8, 4, 7, 0, 9, 9, 5, 2, 3, 4, 7, 0, 1, 2, 5, 4, 1, 3, 4, 3, 9, 1,\n",
       "       6, 0, 7, 2, 7, 1, 6, 0, 7, 9, 8, 4, 6, 6, 0, 0, 2, 4, 6, 2, 7, 4,\n",
       "       0, 4, 5, 5, 9, 0, 0, 6, 1, 0, 9, 4, 5, 6, 7, 6, 8, 9, 1, 1, 1, 8,\n",
       "       4, 2, 2, 8, 2, 3, 6, 9, 0, 4, 7, 9, 8, 3, 4, 3, 4, 3, 3, 7, 7, 2,\n",
       "       1, 6, 4, 8, 4, 3, 1, 8, 8, 1, 1, 1, 0, 7, 3, 2, 4, 8, 5, 0, 4, 3,\n",
       "       5, 1, 9, 4, 7, 7, 0, 5, 5, 8, 9, 0, 4, 2, 8, 5, 0, 4, 4, 1, 4, 2,\n",
       "       8, 7, 6, 2, 7, 0, 8, 3, 2, 6, 8, 5, 7, 6, 6, 3, 4, 2, 9, 7, 8, 4,\n",
       "       9, 7, 7, 5, 5, 0, 8, 0, 0, 5, 1, 4, 0, 1, 7, 6, 0, 3, 6, 1, 5, 7,\n",
       "       3, 7, 1, 0, 2, 5, 3, 9, 6, 7, 8, 5, 8, 2, 5, 6, 1, 5, 7, 5, 4, 1,\n",
       "       9, 0, 5, 1, 2, 3, 5, 9, 1, 2, 9, 4, 5, 6, 6, 5, 2, 3, 2, 1, 5, 5,\n",
       "       1, 6, 1, 6, 1, 6, 4, 2, 1, 0, 0, 5, 7, 4, 3, 8, 6, 4, 3, 8, 5, 1,\n",
       "       6, 3, 4, 3, 8, 7, 4, 6, 1, 3, 8, 2, 5, 3, 8, 5, 2, 4, 7, 9, 3, 4,\n",
       "       9, 9, 4, 8, 9, 9, 4, 8, 3, 8, 5, 8, 0, 6, 2, 5, 5, 5, 7, 7, 2, 8,\n",
       "       4, 0, 0, 0, 3, 7, 6, 4, 9, 8, 3, 7, 8, 7, 3, 0, 5, 3, 4, 4, 5, 3,\n",
       "       8, 9, 2, 9, 1, 7, 2, 4, 9, 5, 8, 7, 4, 3, 6, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weights = model.conv1.weight\n",
    "weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.conv1.weight = weights\n",
    "model.conv1.weight"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "features.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([500, 1, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "model.conv1.forward(features).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([500, 32, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "dir(model.conv1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_tracing_name',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv2d_forward',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'in_channels',\n",
       " 'kernel_size',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'out_channels',\n",
       " 'output_padding',\n",
       " 'padding',\n",
       " 'padding_mode',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'stride',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'transposed',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'zero_grad']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "e023d14327a5b66dc5b0438d9f5b474907bdd56e13f908e7e179933d5814e4c8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}